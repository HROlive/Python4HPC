{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd65eca-8296-4878-8416-f9825eadba86",
   "metadata": {},
   "source": [
    "# Data Analytics with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c86e5-1896-4dff-81a7-afaedc793660",
   "metadata": {},
   "source": [
    "To begin with, we will concentrate on pandas, as it has the most sophisticated API. Both, cuDF and Dask replicate pandas' API, but do not incorporate all functionalities and methods. We will go through Dask and cuDF in subsequent notebooks.\n",
    "One of the main take-away messeges of this part of the course should be:\n",
    "Whenever your data set fits in memory and operations on it execute in an acceptable time frame, you should stick with pandas. When you want to leverage the advantages of GPU acceleration, cuDF is your best friend and should you need to harness the power of parallel execution on CPUs, go with Dask. However, do not expect everything you are familiar with in pandas to work with cuDF or Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd885249-74e5-46d5-a1da-01e76c25600e",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "# import cudf\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22999211-1c72-4c09-bdce-f08740cf3c7a",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "You can use pandas, cuDF and Dask to load a wide range of file formats (csv, xls, parquet, json, hdf, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5025ddf-0b0a-4e70-b231-7ac63bc9009d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Single files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ab41d-3601-4fff-8e8e-2af2a99689a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv(\"./data/nycflights/1999.csv\") # Reads one csv file and displays it as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114090b-6680-4844-a211-b0c8d8b29155",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head() # Displays the dataframe with the first 5 entries. If you want to view a differnt number of rows, enter the number into the brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2397783-32b4-4846-ba28-628415813a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.tail() # Displays the last 5 entries of the dataframe. You can choose the number of rows that should be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e19e5e-4cd8-4e41-b13f-53ff9dbbb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.dtypes # Returns the data type of each column. Objects are bacically strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b0adf-f4dd-44c7-9014-f359361b9e08",
   "metadata": {},
   "source": [
    "### Multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfb810-53be-4a8c-8404-0826c63eff04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = glob.glob(\"./data/nycflights/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a331d3-454a-48d0-b637-2ef3c25a0d7f",
   "metadata": {},
   "source": [
    "To read multiple files into one dataframe, you need to concatenate each one with a for-loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31c597-1c52-44af-a0eb-adc20189f223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf = pd.concat(pd.read_csv(f) for f in filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320596f-3ecd-4159-b8a1-035471dee763",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d23464-ab5c-4056-b3b4-4f0988d1121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbe70e-9bad-4194-9143-5db21a45ca0a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Introduction to Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064630c-06dd-4382-954e-ae7808c4b017",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "### Series\n",
    "The pandas documentation describes a series as such:\n",
    ">One-dimensional ndarray with axis labels (including time series).\n",
    "Labels need not be unique but must be a hashable type. The object supports both integer- and label-based indexing and provides a host of methods for performing operations involving the index. Statistical methods from ndarray have been overridden to automatically exclude missing data (currently represented as NaN).\n",
    "\n",
    "In this coure we will no be focussing on series, but should you need to get to know the basics, you can go through the short introduction by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a28ca8-3bf4-46bd-a881-da93a8b607a2",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj = pd.Series([-4, 6, -2, 1]) # This is how you create a pandas series from a Python list\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e243d9-aa2b-4845-b3c7-28fee6681ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0a51a-d4a9-4040-8601-cff7e1c6be80",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj.index  # Just like range(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09292837-6e20-41f8-8dbd-6b1826e9b4df",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj2 = pd.Series([-4, 6, -2, 1], index=['w', 'z', 'y', 'x']) # The index doesn't need to be numeric. Let's change it!\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebb49d-6b10-4e21-ad27-6cf5aaf7c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61089c7e-be43-410e-822a-729a940de318",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2['y'] # Values can be selected with the label...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aef8f2-bc8f-4396-a594-10e9021a78c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[2] # ...or the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aaee2e-295e-4c70-b164-016167ee02c9",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj2[\"w\"] = 0 # Values can be re-asigned\n",
    "obj2[[\"w\", \"x\", \"y\", \"z\"]] # You can pass a Pyhon list with index numbers or labels for calues you want to select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d3ca6c-c2b0-46e1-9df3-70ef4fd909d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 # The operation above has changed nothing in our series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117e7b1-8b2a-4a45-8332-215c33f88113",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj2[obj2 > 0] # Just as in NumPy-like operations, you can filter using a boolean array...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b52786-b083-436b-9319-19e9a2d16515",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 * 2 # ....or perform scalar multiplication...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209027bc-66da-428a-9340-111a5a2003d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(obj2) # ....or apply mathematical functions. This will always preserve the index-value link...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b3f1d6-5871-4a17-a291-fda9d3470e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 # ...and does not change the actual series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba93948-fdc2-4fe3-a00a-70a1b68831d4",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "'y' in obj2 # You can use series instead of a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e79011-f871-4ccd-ae4e-5c0498c137e8",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sdata = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}\n",
    "obj3 = pd.Series(sdata) # If you have a Python dict, you can create a series from it by passing the dict\n",
    "obj3 # The series object automatically uses the dict's keys as indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221dbec-ecd1-49eb-944f-126abb9b8f7a",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]\n",
    "obj4 = pd.Series(sdata, index=states) # Let's override the default index or key order\n",
    "obj4 # Since \"California\" was not a key in our dict, we have a missing value or NaN (not a number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4d6c4-175a-47fb-9bc7-f9e3aa45be0c",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj4.isnull() # You can use the isnull (or notnull) method to detect missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af221167-1705-4bbd-a0be-b389c2a8f69e",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj3 + obj4 # You can apply arithmetic operations to series. The result will automatically align by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0cb55-6e08-466b-a7b8-7fbd1e70b97c",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj4.index = [\"Bob\", \"Steve\", \"Jeff\", \"Ryan\"] # You can easily rename the index entries\n",
    "obj4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7936978-3458-4458-a611-c4896e157ea0",
   "metadata": {
    "editable": true
   },
   "source": [
    "### DataFrame\n",
    "The docstring of the DataFrame class describes this object like this:\n",
    ">Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
    "    Data structure also contains labeled axes (rows and columns).\n",
    "    Arithmetic operations align on both row and column labels. Can be\n",
    "    thought of as a dict-like container for Series objects. The primary\n",
    "    pandas data structure.\n",
    "\n",
    "In this course we will mainly be focussing on DataFrames, as they are the workhorse in pandas and ilustrate the capabilities of cuDF and Dask really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cf809-e7ed-4ccd-beea-623f0bb4fa5d",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n",
    "        \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "frame = pd.DataFrame(data) # There are many ways of how to construct a DataFrame, but this is one of the most common ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da959504-7cd7-468c-94eb-fe42030258cb",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a165e5a4-703b-4432-8d57-95a812c7e654",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa386ef3-5fd7-4093-98dc-6179a7b3bb3c",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\"]) # Let's re-arrange the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6513a90-a30a-4421-b93b-c20e4d35ca37",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame2 = pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\", \"debt\"], # Here we create a new DataFrame with new columns and and indices\n",
    "                      index=[\"one\", \"two\", \"three\", \"four\",\n",
    "                             \"five\", \"six\"])\n",
    "frame2 # The column \"debt\" does not currently have any values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da536dae-79d2-43ce-913e-2f765182996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ee543-8b4d-4dd7-b0a7-67487f5fd684",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame2[\"state\"] # A column can be retreived as a series either by dict-like notation...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5081b-faef-4c21-a2cf-2934dabaa791",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.state # ....or by attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f2f44-d00b-461c-913c-06d0d0161957",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2[[\"state\"]] # Pass a Python list to get a Dataframe instead of a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bffefd-c1f2-4ffe-a117-5e5f9d9c47e4",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame2.loc[\"three\"] # To retrieve a row, use the loc attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d148d1-b811-4dbb-9cf0-7244320d88bd",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame2[\"debt\"] = 16.5 # Columns can be modified by assignment. Here, we assign the empty \"debt\" column a scalar value\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a0c91-75c7-4b44-8e0f-f308892d3e62",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame2[\"debt\"] = np.arange(6.) # Here we assign an array of values. When you assign lists or arrays to a column, the value's length must match the length of the Dataframe.\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314bfe2-98d7-426d-a75b-e97084b39afc",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five']) # If you assign a series, its labels will be realigned exactly to the DataFrame's index, inserting NaNs in any holes\n",
    "frame2['debt'] = val\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d541c-d203-47ad-83b6-525c7e1e3f07",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame2[\"eastern\"] = frame2.state == \"Ohio\" # Assigning a column that doesn't exist creates a new column\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5446a-9a96-46c1-b6f0-b2b932b531c3",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "del frame2[\"eastern\"] # Should you want to delete a column, use the del keyword....\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e40cc-2ff0-4cd9-99df-de0714741575",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.drop([\"debt\"], axis = 1, inplace = True) # ...or the drop method. Here you have to specify the label and axis. If you permanently want to delete the column/row, set inplace=True\n",
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d9091-0534-4138-b24f-34096ec19879",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "### Index Objects\n",
    "panda's index objects are responsible for holding the axis labels and other metadata (like the axis name or names). Any array or other sequence of labels you use when constructing a series or DataFrame is internally converted into an index. Index objects are immutable and thus cant't be modified by the user, making it safer to share index objects among data structures.\n",
    "In this course we will no discuss index objects, but feel free to go through that section in your own time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9cff52-2de9-4061-9ffb-3985a1bd92a9",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj = pd.Series(range(3), index=[\"a\", \"b\", \"c\"])\n",
    "index = obj.index\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aef52e-138f-4b14-8c57-d671b0d51668",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "index[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723c559-72e7-4eb4-ae51-f942b38d50aa",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "labels = pd.Index(np.arange(3))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1367c-7038-4449-b195-dded4daaf32b",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj2 = pd.Series([1.5, -2.5, 0], index=labels)\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4629c-58c2-4059-a83d-adaa6f8b2f21",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj2.index is labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d495fcc-b5c0-4a5e-a6aa-6ee0a6fd2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef8a60-c9bc-419e-a4b6-e699d4fe606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb1ae0-19c5-4992-aab3-ece4a53da935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"state\" in frame2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f0728-34a7-40db-b4e2-f72771e6ed57",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"one\" in frame2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c931e0c-4526-4dc1-b2f2-5f21e23b3099",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dup_labels = pd.Index(['foo', 'foo', 'bar', 'bar']) # A pandas index can contain duplicate labels. Selections with duplicate labels will select all occurrences of that label.\n",
    "dup_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ba48a-b7f5-4a55-a479-4084a0ce1f10",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Essential Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc70675-2e7c-4e91-8594-2c2fb9890915",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Reindexing and Renaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5486d3-826f-41be-a1f1-707e1d444ac8",
   "metadata": {},
   "source": [
    "Let's create a random DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c9da5-beb8-4483-9571-72ba48e20469",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(81).reshape((9, 9)),\n",
    "                     index=[\"a\", \"c\", \"i\", \"d\", \"f\", \"g\", \"b\", \"e\", \"h\"],\n",
    "                     columns=[\"ba\", \"be\", \"bi\", \"bo\", \"bu\", \"ca\", \"ce\", \"ci\", \"co\"])\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252d2ec-8321-4f05-96c2-bb847aecde87",
   "metadata": {},
   "source": [
    "Reindex moves whole rows about (including values), not just the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b96a7e-efc9-429f-b027-3dfe47c392f1",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame2 = frame.reindex([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\"])\n",
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003a835-c713-477c-8f65-e2e7913796e3",
   "metadata": {},
   "source": [
    "This is a list of Austrian provincial capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b241f74-1754-4f3a-96da-021fb98e428d",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cities = [\"Vienna\", \"Salzburg\", \"Linz\", \"Graz\", \"Bregenz\", \"Innsbruck\", \"Klagenfurt\", \"Eisenstadt\", \"Sankt Pölten\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d70481-ef2b-4d65-ab6a-e643078b05eb",
   "metadata": {},
   "source": [
    "With set_axis we can rename columns or indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0492a1a-3486-46d2-8e5d-5a5f11775157",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame2.set_axis(cities, axis=1, inplace=True)\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f669aa-6c4f-44cd-b9a6-33c14882ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_new_order = [\"Salzburg\", \"Vienna\", \"Graz\", \"Linz\", \"Bregenz\", \"Innsbruck\", \"Klagenfurt\", \"Eisenstadt\", \"Sankt Pölten\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa936c-db28-404e-a74e-4388957968f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame3 = frame2.reindex(columns = cities_new_order) # As before, should we want to change the order of columns, we use reindex.\n",
    "frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048aa08-e2e7-43d0-97f0-f86473384f43",
   "metadata": {},
   "source": [
    "Now, let's work on the flight DataFrame from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ee7b7-d099-4bdb-b47d-dce1ec1dd119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf # Just to remind us how that DataFrame looked like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b93028-b531-48eb-b13d-b6f079ee8b7d",
   "metadata": {},
   "source": [
    "The indices do not match the number of rows, so let's reset the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7e5c6-d4ac-44d7-a1e9-105db09afdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2 = pdf.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3695c-293a-40ce-ba94-c4cfc7a8f3e4",
   "metadata": {},
   "source": [
    "We would like to combine year, month and day into a date column. To do so, we first need to rename the columns, according to the expected keywords in the next command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321e5b4-d915-4bfe-802e-10bfd4828588",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2.rename(columns={\"Year\":\"year\", \"Month\":\"month\", \"DayofMonth\":\"day\"}, inplace=True)\n",
    "pdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef995d2-84d6-45d9-ba6f-1bdeb5f040ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2[\"date\"] = pd.to_datetime(pdf2[[\"year\", \"month\", \"day\"]]) # Now, we can combine the three columns into a new date column....\n",
    "pdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81417fe7-7b8a-4b9a-be33-ae6b6e825b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2.dtypes # The date column indeed has the datetime datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b9677-a961-4e01-9891-c234e35bb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2.set_index(\"date\", inplace=True, drop=True) # .....and set the date as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59883bfb-4e90-4cea-aac9-869845e83f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0cfd5b-4406-459b-9516-79b9ecc3658c",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca7e6f-6e8b-438a-9152-c67a5cf678e4",
   "metadata": {},
   "source": [
    "We use the notna() method to select all the rows without missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb79abc-3441-46e8-8190-460333ee7c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf2[pdf2[[\"year\", \"month\", \"day\", \"DepTime\", \"ArrTime\", \"FlightNum\", \"ArrDelay\", \"DepDelay\", \"Origin\", \"Dest\", \"Cancelled\"]].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf63c9-6eb1-4ff3-b71a-b7cf82f06bf8",
   "metadata": {},
   "source": [
    "The isna() method does the exact opposite and selects the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ea362-6c78-49f6-add5-02213df856cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2[pdf2[\"DepTime\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d685c-4101-48b8-8e12-103c8b94e1e2",
   "metadata": {},
   "source": [
    "Let's reduce our DataFrame to make it a bit more accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f185f3-cf37-4fc3-b948-cfde4ed8f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf3 = pdf2[[\"year\", \"month\", \"day\", \"DepTime\", \"ArrTime\", \"FlightNum\", \"ArrDelay\", \"DepDelay\", \"Origin\", \"Dest\", \"Cancelled\"]]\n",
    "pdf3.shape # This gives you the number of rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78eadc8-8b95-48a2-98c6-15a510f133e4",
   "metadata": {},
   "source": [
    "To select rows with actual values we use the notnull() method. Unfortunately, we cannot pass a list with column labels, but have to repeat the command for each clolumn name. AS the cancelled flights are the ones wich have no departure and arrival times, we automatically select the flights which were not cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a69b15-cf09-4839-95f0-5207dfe3706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf3[pdf3[\"Cancelled\"]==1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89319f-81b5-4976-bf82-b6587a16afc2",
   "metadata": {},
   "source": [
    "We would like to use the cancellations at a later point, therefore we create a new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348617d-c7a4-4030-a932-edc2e6459942",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4 = pdf3\n",
    "pdf4 = pdf4[pdf4[\"DepTime\"].notnull()] # notnull() is equivalent to notna()\n",
    "pdf4 = pdf4[pdf4[\"ArrTime\"].notnull()]\n",
    "pdf4 = pdf4[pdf4[\"ArrDelay\"].notnull()]\n",
    "pdf4 = pdf4[pdf4[\"DepDelay\"].notnull()]\n",
    "pdf4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a2acb1-a15e-48b3-9b59-bac4a6cd8515",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca0a2f1-0291-4cea-9358-781f36f1467e",
   "metadata": {},
   "source": [
    "We would like to transform the departure time and arrival time into a datetime format. However, first we need to transform the float into a correctly rounded integer. For that we use the round() and astype() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2297a-b9ed-4494-9103-9465c92ccaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4[[\"DepTime\", \"ArrTime\", \"ArrDelay\", \"DepDelay\"]] = pdf4[[\"DepTime\", \"ArrTime\", \"ArrDelay\", \"DepDelay\"]].round(0).astype(int)\n",
    "pdf4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473637ee-d675-4fdd-8011-b0f32f0e0702",
   "metadata": {},
   "source": [
    "To transform the number into a datetime format we first need to transform it into a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852b54e-299d-4cb7-b1d1-8ee39ad3cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4[[\"DepTime\", \"ArrTime\"]] = pdf4[[\"DepTime\", \"ArrTime\"]].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bb0d9-de92-49f2-9231-1dabf12a76b7",
   "metadata": {},
   "source": [
    "Some of the strings only have three characters. With this lambda function we make sure that all of them are made up of four characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa253b47-da59-427b-9fb9-f143127be1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf4[\"DepTime\"] = pdf4[\"DepTime\"].apply(lambda x: x.zfill(4))\n",
    "pdf4[\"ArrTime\"] = pdf4[\"ArrTime\"].apply(lambda x: x.zfill(4))\n",
    "pdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e530e-a7ec-4088-9783-c31f3b1e5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4[pdf4[\"DepTime\"].str.len()!=4] # let' just make sure that that all values have four characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd10c8-4fe8-4eef-b64c-bfb48d3fb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4.dtypes # The DepTime and ArrTime are indeed strings (objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bc358-0bd7-4b13-bff4-bca677e3cdb8",
   "metadata": {},
   "source": [
    "We can finally transform these columns into datetime datatypes. Here we pass exact=False, incase some of the strings do not have the ideal format. The .dt.time at the end makes sure, we only select the time and not the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43164f-0cba-49fa-bf37-6767902ce857",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4[\"DepTime\"] = pd.to_datetime(pdf4[\"DepTime\"], format=\"%H%M\", exact=False).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92a840-2f23-462d-97f5-50e129417815",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4[\"ArrTime\"] = pd.to_datetime(pdf4[\"ArrTime\"], format=\"%H%M\", exact=False).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa73e5-fe5b-4a31-a39e-0649f8098992",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40a957-c95c-4098-a141-bb8c39f6b589",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Dropping Entries from an Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbbadb9-0c41-40d0-936c-886929686a72",
   "metadata": {},
   "source": [
    "The drop() method drops entries from axis 0 (rows) by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc9a46-1e44-4f80-a290-26287c15510f",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame3.drop([\"d\", \"g\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb85b4-19d5-4513-a388-fa5565d20ce1",
   "metadata": {},
   "source": [
    "You need to pass axis=1 or axis = \"columns\" to drop columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67fec02-47ae-40ca-8569-ffa39df3009e",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame3.drop([\"Eisenstadt\", \"Sankt Pölten\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c035cd-38c9-43ca-b3fc-552477768c44",
   "metadata": {},
   "source": [
    "Maybe you noticed, that the drop method does not change the original dataframe by default. If you wish to do so, pass inplace=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961123f-ac68-4fad-ad35-99e58d81deae",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame3.drop(\"Vienna\", axis=1, inplace=True)\n",
    "frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12aa227-bd97-43c6-8575-dd4d658e957b",
   "metadata": {},
   "source": [
    "How would you drop the \"year\", \"month\" and \"day\" column in the pdf4 DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96455fe0-361b-4962-b9b6-e01c61be97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f75df2b-5756-428e-b8bc-aefd71b23fd4",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb043012-6cdb-49bb-953d-1f14d4f135b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf4.drop([\"year\", \"month\", \"day\"], axis=\"columns\", inplace=True)\n",
    "pdf4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5838a5-306c-4d0e-8a3d-ea610c9a0107",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Indexing, Selection, and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8846b3-71bf-487d-b659-5261ed60decd",
   "metadata": {},
   "source": [
    "Passing a single element or a list to the [] operator selects columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85fa7c-aecd-4d16-800c-0b69cc8555c7",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame3[\"Salzburg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca53d0d-e452-49f1-94f8-f6c637378903",
   "metadata": {},
   "source": [
    "To select rows use the dataframe[3:7] slicing sytax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23586447-6d29-4bbc-a3b7-128fe1e9869b",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame3[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab56025-444c-4400-be8e-f109f4157f9d",
   "metadata": {},
   "source": [
    "For DataFrame label-indexing on the rows, use loc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f7302-e5b4-40d8-a390-ececf7ce3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.loc[[\"a\",\"b\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8090618-7b4e-4753-b32f-9b1d27e283cd",
   "metadata": {},
   "source": [
    "With loc you can also select rows and columns at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868deb16-c9af-4bfb-af15-37584d349996",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.loc[[\"a\",\"b\"],[\"Salzburg\", \"Graz\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a403af-aedf-4713-b9ef-ede14c17bbc7",
   "metadata": {},
   "source": [
    "As we now have a duplicate indices the loc method gives all entries with that date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9314866-b191-43ad-80c1-43d4ed496a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4.loc[\"1999-01-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f971b24-f3fa-4c51-acf9-1115720abbd8",
   "metadata": {},
   "source": [
    "Let's select data with a boolean array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2112da6-b6b1-407b-a05e-b58e6279f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3 < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91a965-13b9-4b4f-8107-b4f90115b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3[frame3[\"Salzburg\"] < 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af6022a-f68f-4f30-ad7c-44d0dfe6c3ca",
   "metadata": {},
   "source": [
    "Here we set the values in column \"Salzburg\" which are below 20 equal to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d24849-0a81-4f72-8a1e-57021525f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3[\"Salzburg\"][frame3[\"Salzburg\"] < 20] = 0\n",
    "frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2459d3-3473-4a7e-8996-d1554f5236ec",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Arithmetic and Data Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea58e6c-14ac-456e-868a-8358648d7fa5",
   "metadata": {},
   "source": [
    "In arithmetic operations between DataFrames, the internal data alignment indtroduces missing values in the label locations (indices and columns) that don't overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac9741-5ff3-4220-8fe6-943554ba3c59",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame4 = pd.DataFrame(np.arange(36).reshape((6, 6)),\n",
    "        columns = [\"Vienna\", \"Salzburg\", \"Graz\", \"Bregenz\", \"Innsbruck\", \"Eisenstadt\"],\n",
    "        index = [\"a\", \"c\", \"d\", \"f\", \"g\", \"i\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fc8c0-44e9-44ff-89db-d6beec40bf29",
   "metadata": {},
   "source": [
    "Adding these together returns a DataFrame whose index and columns are the unions of the ones in frame3 and frame4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed1851-b1b6-4ed6-af32-4b05e3c66ddc",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame3 + frame4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc9db4-4a40-46cc-a87a-bd267dd0bef0",
   "metadata": {},
   "source": [
    "Use arithmetic methods, if you want to fill the not overlapping areas with specific values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4aa8b-1946-44f4-9252-d4b94cedfbfd",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame3.add(frame4, fill_value=0) # Now only areas where data is missing in both Dataframes have NaN entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82991d07-f2bf-4a27-a0e9-b1cf1a41281f",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Function Application and Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ff712-bb1d-476c-a7db-e6b4562731ff",
   "metadata": {},
   "source": [
    "NumPy ufuncs (element-wise array methods) also work with pandas objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8ebe6-8ac6-4a07-bbe3-7ac1a34bc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(frame3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76d9e3-1a33-469d-80ac-ab5b4c311d26",
   "metadata": {},
   "source": [
    "Another frequent operation is applying a function on one-dimensional arrays to each column or row. Here the function f, which computes the difference between the maximum and minimum of a series, is invoked once on each column in frame3. The result is a series having the columns of frame3 as its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787391f-7811-4b50-870b-f32bd6e27489",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f = lambda x: x.max() - x.min()\n",
    "frame3.apply(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6963087-12e6-476a-a422-a42142eea6d0",
   "metadata": {},
   "source": [
    "If you pass axis=\"columns\" to apply, the function will be invoked once per row insteads:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b6569-98e4-4d17-a02c-5dc77d622d6f",
   "metadata": {},
   "source": [
    "With the applymap method you can use element-wise Python functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca388bf0-ba9a-4e4c-9df8-60616457a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "format = lambda x: \"%.2f\" % x # This function rounds each value to the second decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb250dc-2ed7-46c0-a299-e349693c0a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.applymap(format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1065e01a-e03f-4bbf-ab35-ccac39d22f00",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9cde2-5740-4e16-85f7-ca996deda50f",
   "metadata": {},
   "source": [
    "Let's create a new DataFrame with random values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a646148-94bc-4639-8b2c-f333651e6ad3",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "frame = pd.DataFrame(np.random.randint(0,50,81).reshape((9, 9)),      # Let's create a random DataFrame\n",
    "                     index=[\"a\", \"c\", \"i\", \"d\", \"f\", \"g\", \"b\", \"e\", \"h\"],\n",
    "                     columns=[\"ci\", \"be\", \"bu\", \"bo\", \"bi\", \"ce\", \"ca\", \"ba\", \"co\"])\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5428c2-c0e8-41a6-974f-57ee64332c63",
   "metadata": {},
   "source": [
    "We can sort the DataFrame by row with the sort_index method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bec000-84f6-4f77-bc14-f9a538ddfe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe96d170-688d-42d1-b4a1-7c9b40fb69e1",
   "metadata": {},
   "source": [
    "If we need to sort column-wise, we have to pass axis=1 or axis=\"columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328621e-d959-45fd-a604-e2f5452f2a9c",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bfd3ba-51aa-48ab-805c-899922b9f57a",
   "metadata": {},
   "source": [
    "If you actually want to sort the values row- or column-wise, you need to use the sort_values method and pass the row or column you want to sort by. You can also pass a list of rows or columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2694ea9-927a-489b-85ad-612cc6c5c3a2",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame.sort_values(by=[\"ba\", \"be\"]).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ed17e-3c3e-4a88-a509-6ce6d0c769dd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Summarizing and Computing Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd2291-af8b-4a68-918e-95c613c22e69",
   "metadata": {},
   "source": [
    "The following methods redurn a series containing column reductions (sums or mean etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa6f6d-b164-40ba-ae96-5e624ae3f4bf",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa1466d-37a6-46a3-ad6f-275aeff688f8",
   "metadata": {},
   "source": [
    "For row wise reduction pass axis=\"columns\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f97461-ce6c-42af-b1c1-b8d2e3611db0",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame.sum(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6026ce-c516-40af-8601-9afcd17ae722",
   "metadata": {},
   "source": [
    "NA values are excluded unless the entire row or column is NA. Do disable this pass skpna=False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272c337-eeca-47fa-9a08-d003900249d4",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame.mean(axis='columns', skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d1909-bffd-4806-96f4-5e486951f4eb",
   "metadata": {},
   "source": [
    "To produce multiple summary statistics in one shot, use the describe() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5bbaf-7025-4acf-bf3e-637be0c805e9",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b86c43-a659-4097-ba7f-2349973249a0",
   "metadata": {},
   "source": [
    "On non-numeric data, describe produces alternative summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fb6e9-b10f-48d6-bd55-3b5fcecd5e15",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obj = pd.Series(['bli', 'bli', 'bla', 'blu'] * 5)\n",
    "obj.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2884fc-37e2-4c71-a387-73d627a0ea37",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Correlation and Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f50581-0f47-4d62-b3d4-0cbe2e865cc2",
   "metadata": {},
   "source": [
    "To demonstrate correlation and covariance we will download a few stock tickers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf2b877-d7ed-46e0-b645-1ed8fdf200a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bcab72-ccd9-4478-a3a6-91c5951e3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {ticker: web.get_data_yahoo(ticker) for ticker in [\"AAPL\", \"IBM\", \"MSFT\", \"GOOG\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afca2c4-b42d-40ca-b928-d657f3f13ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.DataFrame({ticker: data[\"Adj Close\"] for ticker, data in all_data.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099e6af-7b5f-4f23-9900-e82b965d4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = pd.DataFrame({ticker: data[\"Volume\"] for ticker, data in all_data.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45135e4f-df54-46a4-9f18-6541768f12d3",
   "metadata": {},
   "source": [
    "Here we compute percent changes of the prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8233b1-9e56-4d7e-b965-0446063301e1",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "returns = price.pct_change()\n",
    "returns.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77d239-96e7-4797-bfc4-8bc026b22ed7",
   "metadata": {},
   "source": [
    "This is how you compute the correlation and the covariance of values in two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0176b05-941a-4978-8c88-86c9ad68b820",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "returns['MSFT'].corr(returns['IBM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156d125-93ba-4439-b880-d1f08ef546d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns['MSFT'].cov(returns['IBM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a4355-4175-41ba-a2b2-6d33314129cb",
   "metadata": {},
   "source": [
    "If you need a full correalation or covariance matrix of your DataFrame, just enter df.corr() or df.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5983bf-02e6-40a6-959e-db9d9cadd17c",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "returns.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bb9ee-60b6-4ae0-aa2e-f819d7ef2299",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Unique Values and Value Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48176f01-d4c2-4a46-86e4-78c666bb547d",
   "metadata": {},
   "source": [
    "To find out how many unique values you have in a row or column, use the unique() or vlaue_counts() methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff8ada-d4c8-46eb-bb82-4f76420db7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4[\"Origin\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5599ecf-d23c-4ef2-b5b0-8c33ee599598",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4[\"Origin\"].value_counts(sort=True) # The output is not sorted by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885a245-f7bc-425e-85e2-d6a03651fe81",
   "metadata": {},
   "source": [
    "How would you find out wich destination is mentioned most often in our pdf4 DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61feb364-bd8d-4993-841f-473eedf1887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's your turn:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a089cdd7-c87c-454a-a422-d7ab07ad5797",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031463a-54a5-47f3-93ac-8fd2d3d9da9e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf3[\"Dest\"].value_counts(sort=True) #ORD is Chicago's O'Hare airport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17504b0c-c8da-42c5-983d-eef7a37f464c",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3040592-09ba-4901-a854-86298b70d3bd",
   "metadata": {},
   "source": [
    "### Combining Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc2b26-0b51-4af7-8c39-ad6764d55b69",
   "metadata": {},
   "source": [
    "Merge and join operations combine datasets along axis 0 (rows). To demonstrate how to use these functions, let us create two new datasets first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a0fc7-524d-4806-888e-f37183754e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"a\":[1,1,1,2,2,3,3],\n",
    "                    \"b\": np.random.randint(0,99,7)})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb7a2b-68de-45b4-a8c7-772511000b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"a\":[1,2,3,4,5],\n",
    "                    \"c\":np.random.randint(0,99,5)})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724bb67-72bf-499d-97f1-278f59136dab",
   "metadata": {},
   "source": [
    "As you can see in the text cell, the merge() function automatically uses overlapping column names as keys, whithout us having to specify one. It is good practice, however to explicitly say on which columng they should merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639e447-cad5-41db-9101-28055015f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01383daa-33ab-4034-ac22-7c8809e9956a",
   "metadata": {},
   "source": [
    "You may also notice that values 4 and 5 from column a are missing after the merge. This is because datasets do an inner merge by default, meaning that we have the common set found of both tables in the output. We can however pass how=\"outer\" or \"left\" or \"right\" do get the union of the keys or youse the one of the left or right DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113f990-1d6b-4ffd-b19d-ef3b8a31a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on=\"a\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35abba2-e86f-4330-9c17-4dcd8ac3da2d",
   "metadata": {},
   "source": [
    "DataFrame has a convenient join instance for mergin by index. It can be used to combinde multiple Dataframes with the same indexes but without overlapping columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8ba8e-4ca5-411b-8122-75928f93142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({\"c\":np.random.randint(0,10,7),\n",
    "                    \"d\": np.random.randint(0,99,7)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4485e-a646-421b-9e88-f926591d8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join(df3, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e57d73-ecb4-4b0e-9ee3-a10d46f8bc46",
   "metadata": {},
   "source": [
    "Another form of Dataset combination is called concatenation. You can use that to extend DataFrames along axis 1 (columns) as well as 0 (rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e8ad3-e5e2-4aa5-972d-4c2a5f3452d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf7cad-8419-4810-9ce9-a25106c1c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734dd28e-3962-4499-8787-a295f1e55190",
   "metadata": {},
   "source": [
    "### Reshaping DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d9fb8-5d83-483a-83cb-838afb72dd4e",
   "metadata": {},
   "source": [
    "The \"stack\" action rotates columns in the data to the rows and uses hierarchical indexing, \"unstack\" does the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f0942-40cf-4854-b3ab-83db58346d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = frame3.stack()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0af73c-e577-4ceb-955b-fd8aeb05fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.unstack() # This can introduce missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05462f6-e249-4c1b-9515-e4e147246c88",
   "metadata": {},
   "source": [
    "The pivot() method returns a reshaped DataFrame organised by given index/column values. Pivoting your data allows you to reshape it in a way that makes it easier to understand or analyse. Often you’ll use a pivot to demonstrate the relationship between two columns that can be difficult show before the pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f188b-5e45-4f7f-96b5-b89851935401",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv('https://gist.githubusercontent.com/alexdebrie/b3f40efc3dd7664df5a20f5eee85e854/raw/ee3e6feccba2464cbbc2e185fb17961c53d2a7f5/stocks.csv')\n",
    "stocks # Let's import a new dataset to demonstrate the pivot method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03ac74-4942-4027-b53a-26a838dab8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pivot lets us visualise the change in volume over time for each stock much easier\n",
    "stocks.pivot(index='symbol', columns='date', values='volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a026d9f-8fbd-4d4c-b1bb-0802240cf9da",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20dc58b-5f59-4c14-ab10-6a7745bd376b",
   "metadata": {},
   "source": [
    "Each group operation does a slit-apply-combine action. The data is split into groups based on one or more keys along a particular axis. Then a function is applied to each group, producing a new value. Finally, the results of all those function applications are combidned into a result object.\n",
    "\n",
    "   <img src=\"images/Groupby_grafik.png\" align=\"center\" width=\"50%\">                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb7241e-8370-465a-881b-ff20ba57b637",
   "metadata": {},
   "source": [
    "Let's get our pdf4 flight dataset again and see what the mean departure delay for each is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f5b88-d993-432d-8d0a-f6682d4b249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220c4c5-8eee-4b9d-b981-db85e09fe22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = pdf4[\"DepDelay\"].groupby(pdf4[\"Origin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a64a2-9aa6-4680-90c7-82bd92758ae6",
   "metadata": {},
   "source": [
    "This code is equivalent with the one above.\n",
    "In subsequent notebooks you will see more of this syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581a2e1-3878-4c60-a1e9-84342f201d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = pdf4.groupby(\"Origin\").DepDelay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e207823-6a83-4ee2-8564-e0ba8bc5b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd26a83-100c-4d43-9bda-dcdcce22f797",
   "metadata": {},
   "source": [
    "How would you determine the median arrival delay for each destination airport?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fcb1b2-eb89-4f43-8caf-6718248e7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's your turn to code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a8e4f-b7d1-492d-bb4a-247bedd54914",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82948b5-3b17-4c7d-9964-0934d822e86a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_arrival_delay = pdf4[\"ArrDelay\"].groupby(pdf4[\"Dest\"]).median()\n",
    "grouped_arrival_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e2c7c-af75-4b26-9d33-13e9a347fea9",
   "metadata": {},
   "source": [
    "Now, I'm curious what the maximum median arrival delay is. Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334aa350-97b8-4e79-ab58-44751351504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_arrival_delay.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726853d3-b101-4ef6-a7a8-c4991776531f",
   "metadata": {},
   "source": [
    "Which airport is so notorious?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c8e90-4487-4087-9b7c-eaf0c3f43644",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_arrival_delay.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860a8a2-0fb8-43af-a952-369742b208ca",
   "metadata": {},
   "source": [
    "Hang on, JFK? Are there really flights from one of New York's airports to JFK??? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231f27f-bb03-4a0b-946f-ef3b38970fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4[pdf4[\"Dest\"]==\"JFK\"] # Indeed there are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96288c7b-a81d-4dd5-8d6f-0953cd06aff1",
   "metadata": {},
   "source": [
    "How would we go about which of the three Origin airports cancelled the most flights? We have to use the pdf3 dataset again and apply the sum() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff45dfe-ec28-44ee-9dfa-d373e111faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a go:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9116b-ea2f-47e2-a656-692a2d6dd752",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60769b6-1965-4fcb-b117-9bee424eb023",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The sort_values just gives you a better overview in large outcomes\n",
    "pdf3[\"Cancelled\"].groupby(pdf3[\"Origin\"]).sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4cf92-80f7-4acf-9f43-bb5fae4ef14b",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5b3f2-561f-4631-81a3-47a2a7f75a6b",
   "metadata": {},
   "source": [
    "Let's say we would like to save our pdf3 DataFrame as a file. How would we do that? We'll save it in the csv format first. However, we can just as well save it to a json, hdf5 or excel format, to mention just a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1433a145-fa4a-40d5-957f-b2a21bc38060",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf3.to_csv(\"pdf3_nyc_flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a280481-d63a-4501-8465-359e88e29dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf3.to_hdf(\"pdf3_nyc_flights\", key=\"pdf3\") # hdf5 files need a key, as they can contain multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c176a3b-ce1e-4b40-b1c9-b11431147093",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf5 = pdf3.reset_index() # We need to reset the index as json doesn't allow duplicate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051efa44-5230-401c-aa66-863c264eff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf5.to_json(\"pdf5_nyc_flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295be148-da54-4e16-9064-ec44aaf1c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf3.to_excel(\"pdf3_nyc_flights\") # Oops. Our DataFrame is to large for an excel file..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b00bb6-c89a-4434-a07a-6156551e2bd2",
   "metadata": {},
   "source": [
    "Please restart the kernel to release the memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd176cd4-97b9-49fe-b6d8-4bae99036400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4592b427-a945-4ab8-97c9-696e26a9a4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
