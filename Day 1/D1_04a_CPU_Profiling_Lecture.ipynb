{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323c169a-d6fb-41b0-aeb6-c0266d3e58eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722a083-176f-4140-ac32-4565c7bee139",
   "metadata": {
    "tags": []
   },
   "source": [
    "Understanding and locating the bottlenecks of a program is crucial for its optimization, since these bottlenecks (or hot spots) are the parts where most of the running is spent. The profile of a program is essentially composed of a number of counters, timers and locations that together describe how much of its running time the program spends at different regions.\n",
    "In general, there are two approaches to profiling: deterministic profiling and statistical profiling. They differ not only in the precision of their results but also in the overhead they incur on the runtime and how their insights into the resource consumption of a program are gained.\n",
    "\n",
    "__Deterministic profiling__ makes use of trace functions that are inserted into the program that meant to be profiled. They enable the profiler to measure the elapsed time between certain events, such as function calls, function returns, thrown exceptions, and more. \n",
    "\n",
    "__Statistical profililing__ only provides approximate information because these profiles sample the stack frames at regular time intervals, which allows this kind of profiler to analyse them statistically and thereby extract meaningful metrics for the profiled program. Even though the overhead brought about by profiling is usually not insignificant, statistical profilers involve much less overhead than deterministic ones, which comes at the price of less precise profiles.\n",
    "\n",
    "Conveniently, the Python interpreter already includes the mechanisms that are necessary for deterministic profiling. Callback functions, i.e. a function passed as an argument to other functions that are expected to call this passed function, can be inserted at program or interpreter level for various events. Additionally, due the fact that the Python interpreter already causes significant overhead, these callbacks add little overhead on top of that compared to compiled languages.\n",
    "\n",
    "The __call count__, which counts how often a certain function is called, __timers__ and __memory usage__ are common metrics in profilers that can shed light on various program characteristics:\n",
    "* __Hot loops__, i.e. loops with a high number of iterations, can be identified and subsequently optimized\n",
    "* Functions that potentially benefit from __in-lining__ can be spotted by their high call count\n",
    "* Untypical call counts can indicate __bugs__ \n",
    "* High memory usage can help to identify __memory leaks__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d6853-800c-45bb-b1c8-26279ebbadcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `timeit`\n",
    "\n",
    "The `timeit` magic command in the Jupyter allows to measure the time execution of small programs or even single instructions by using the module `timeit`. It is not necessary to import anything explicitely and it is both a cell and a line magic command. `timeit` temporarily turns off garbage collection during the timing, which leads to different results than those obtained from `time`, but GC can be re-enabled as the first statement in the setup string. Practically, `timeit` automatically adjusts the number of repetitions, if it is not stated explicitely. It must be noted that, strictly speaking, `timeit` is to be used for __benchmarking__ purposes only, i.e. the program in execution is neither inspected nor instrumented.\n",
    "\n",
    "___References___\n",
    "* [timeit — Measure execution time of small code snippets](https://docs.python.org/3/library/timeit.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9047dc0e-8b43-4a45-b45c-8a929649f6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Time execution of a Python statement or expression\n",
       "\n",
       "Usage, in line mode:\n",
       "  %timeit [-n<N> -r<R> [-t|-c] -q -p<P> -o] statement\n",
       "or in cell mode:\n",
       "  %%timeit [-n<N> -r<R> [-t|-c] -q -p<P> -o] setup_code\n",
       "  code\n",
       "  code...\n",
       "\n",
       "Time execution of a Python statement or expression using the timeit\n",
       "module.  This function can be used both as a line and cell magic:\n",
       "\n",
       "- In line mode you can time a single-line statement (though multiple\n",
       "  ones can be chained with using semicolons).\n",
       "\n",
       "- In cell mode, the statement in the first line is used as setup code\n",
       "  (executed but not timed) and the body of the cell is timed.  The cell\n",
       "  body has access to any variables created in the setup code.\n",
       "\n",
       "Options:\n",
       "-n<N>: execute the given statement <N> times in a loop. If <N> is not\n",
       "provided, <N> is determined so as to get sufficient accuracy.\n",
       "\n",
       "-r<R>: number of repeats <R>, each consisting of <N> loops, and take the\n",
       "best result.\n",
       "Default: 7\n",
       "\n",
       "-t: use time.time to measure the time, which is the default on Unix.\n",
       "This function measures wall time.\n",
       "\n",
       "-c: use time.clock to measure the time, which is the default on\n",
       "Windows and measures wall time. On Unix, resource.getrusage is used\n",
       "instead and returns the CPU user time.\n",
       "\n",
       "-p<P>: use a precision of <P> digits to display the timing result.\n",
       "Default: 3\n",
       "\n",
       "-q: Quiet, do not print result.\n",
       "\n",
       "-o: return a TimeitResult that can be stored in a variable to inspect\n",
       "    the result in more details.\n",
       "\n",
       ".. versionchanged:: 7.3\n",
       "    User variables are no longer expanded,\n",
       "    the magic line is always left unmodified.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "::\n",
       "\n",
       "  In [1]: %timeit pass\n",
       "  8.26 ns ± 0.12 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n",
       "\n",
       "  In [2]: u = None\n",
       "\n",
       "  In [3]: %timeit u is None\n",
       "  29.9 ns ± 0.643 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
       "\n",
       "  In [4]: %timeit -r 4 u == None\n",
       "\n",
       "  In [5]: import time\n",
       "\n",
       "  In [6]: %timeit -n1 time.sleep(2)\n",
       "\n",
       "The times reported by %timeit will be slightly higher than those\n",
       "reported by the timeit.py script when variables are accessed. This is\n",
       "due to the fact that %timeit executes the statement in the namespace\n",
       "of the shell, compared with timeit.py, which uses a single setup\n",
       "statement to import function or create variables. Generally, the bias\n",
       "does not matter as long as results from timeit.py are not mixed with\n",
       "those from %timeit.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/sw/vsc4/VSC/x86_64/generic/jupyterhub-envs/conda/envs/jupyterhub-dask/lib/python3.10/site-packages/IPython/core/magics/execution.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%timeit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c2eb08-5e08-49b0-8fb9-f5f7fb7a1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = 'This is a string'\n",
    "s1 = 'and this is another string'\n",
    "s2 = 'with the number' \n",
    "i = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554944a6-c156-4aa8-9bbb-872d36fb0ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 ns ± 0.976 ns per loop (mean ± std. dev. of 10 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1_000_000 -r 10 s = f'{s0}, {s1} {s2} {i}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c680c1-d162-4492-8375-e4a96862a890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 ns ± 0.888 ns per loop (mean ± std. dev. of 10 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1_000_000 -r 10 s = s0 + ', ' + s1 + ' ' + s2 + ' ' + str(i) + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3fe2095-e1a5-4369-8f84-ce9230175aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441 ns ± 1.21 ns per loop (mean ± std. dev. of 10 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1_000_000 -r 10 s = '{}, {} {} {}.'.format(s0, s1, s2, str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f396029d-74b3-4d96-afd6-806cdd2e9a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000000 loops, best of 5: 11.2 nsec per loop\n"
     ]
    }
   ],
   "source": [
    "!python3 -m timeit -s \"s0 = 'This is a string'; s1 = 'and this is another string'; s2 = 'with the number'; i = 1337\" \"s = f'{s0}, {s1} {s2} {i}.'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b029547-6ab5-4473-836a-8332b43b61cd",
   "metadata": {},
   "source": [
    "The reason for stating the best time time is that the lowest value gives a lower bound for how fast the given code snippet can be executed on the current computer, while higher values are typically not caused by variability in the speed of the Python interpreter, but by other processes interfering with the timers' accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6394decf-582f-474a-aeb3-2aea3e11ab95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `cProfile` & `profile`\n",
    "\n",
    "`cProfile` and `profile` are both deterministic profilers of Python programs and part of the standard library. The statistics that they produce with their profiles can be formatted into reports with  `pstats` module. To be precise, these two profilers are actually different implementations of the same profiling interface. As the name suggests, `cProfile` is a C extension with reasonable overhead and therefore it is a viable choice also for programs with a longer runtime. On the other hand, `profile` is a pure Python module, which implies significant overhead compared to a C extension, whose interface inspired that of `cProfile`.\n",
    "\n",
    "\n",
    "___References___\n",
    "* [The Python Profilers](https://docs.python.org/3/library/profile.html)\n",
    "\n",
    "$$\\sum_{k=0}^{\\infty} \\frac{(-1)^k}{2k+1} = 1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7} + \\frac{1}{9} - \\dotsb = \\frac{\\pi}{4}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4997e5f-f6d5-4f5d-af50-a5a9321bfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile profiling/sleibniz.py\n",
    "\n",
    "#import cProfile\n",
    "\n",
    "\n",
    "def numerator(i):\n",
    "    return (-1)**i\n",
    "\n",
    "\n",
    "def denominator(i):\n",
    "    return 1.0/(2*i + 1)\n",
    "\n",
    "    \n",
    "def sleibniz(n=1_000_000):\n",
    "    s = 0.0\n",
    "    for i in range(n):\n",
    "        s += numerator(i)*denominator(i)\n",
    "    return 4*s\n",
    "\n",
    "\n",
    "#cProfile.run('sleibniz()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10bef28c-a124-459e-b66c-2df8733d6e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/home/fs70824/trainee19/python4hpc/profiling/sleibniz.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python3 profiling/sleibniz.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9829230-a14b-4c46-a108-183ecf1e5e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         2000004 function calls in 0.918 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.379    0.379    0.918    0.918 2544042676.py:14(sleibniz)\n",
       "  1000000    0.371    0.000    0.371    0.000 2544042676.py:6(numerator)\n",
       "  1000000    0.167    0.000    0.167    0.000 2544042676.py:10(denominator)\n",
       "        1    0.000    0.000    0.918    0.918 {built-in method builtins.exec}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.918    0.918 <string>:1(<module>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%prun sleibniz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89705c7c-bfe0-4fa6-bece-4b0a0bb24bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fleibniz(n=1_000_000):\n",
    "    s = 0.0\n",
    "    for i in range(n):\n",
    "        s += ((-1)**i)/(2*i + 1)\n",
    "    return 4*s\n",
    "\n",
    "\n",
    "def ffleibniz(n=1_000_000):\n",
    "    s = 0.0\n",
    "    for i in range(n):\n",
    "        s += ((-1)*(i%2))/(2*i + 1)\n",
    "    return 4*s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55921a47-d51f-407e-abb9-beadab629175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         4 function calls in 0.407 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.407    0.407    0.407    0.407 2914762232.py:1(fleibniz)\n",
       "        1    0.000    0.000    0.407    0.407 {built-in method builtins.exec}\n",
       "        1    0.000    0.000    0.407    0.407 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%prun fleibniz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc12fea7-b273-4a99-a139-4761a8d44693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.6 ms ± 41 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fleibniz(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24974098-622c-44db-9277-86faec584abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3 ms ± 6.06 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ffleibniz(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f4b572-a0ba-4cf0-bdfd-17428c002b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.2 ms ± 25.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sleibniz(100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f73e3-fe2f-4702-8efd-2da34f59102c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `pstats`\n",
    "\n",
    "The pstats module’s Stats class has a variety of methods for manipulating and printing the data saved into a profile results file:\n",
    "\n",
    "___References___\n",
    "* [Profiler Data Analysis with pstats](https://docs.python.org/3/library/profile.html#module-pstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e94824-317d-4059-8da6-6b8da8b34c0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'performance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcProfile\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpstats\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mperformance\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msleibniz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sleibniz\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create 5 set of stats\u001b[39;00m\n\u001b[1;32m      7\u001b[0m filenames \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'performance'"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from performance.sleibniz import sleibniz\n",
    "\n",
    "\n",
    "# Create 5 set of stats\n",
    "filenames = []\n",
    "for i in range(1):\n",
    "    filename = f'cProfile_stats_{i}.stats'\n",
    "    cProfile.run('sleibniz(100_000)', filename)\n",
    "    \n",
    "#cProfile.run('print %d, sleibniz(10_000)' % i, filename)\n",
    "\n",
    "# Read all 5 stats files into a single object\n",
    "stats = pstats.Stats('cProfile_stats_0.stats')\n",
    "#for i in range(1, 2):\n",
    "#    stats.add(f'cProfile_stats_{i}.stats')\n",
    "\n",
    "# Clean up filenames for the report\n",
    "stats.strip_dirs()\n",
    "\n",
    "# Sort the statistics by the cumulative time spent in the function\n",
    "stats.sort_stats('cumulative')\n",
    "\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb133e2-3074-4eb2-9f8e-3fa05e9b67ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `line_profiler`\n",
    "\n",
    "While the information obtained by `cProfile` already gives a good overview of how much time is spent in a function and where the hotspots are located, which is in many cases sufficient to optimize the code to a reasonable degree, however, sometimes the reason for poor performance lies in a single line of code. In scientific applications, with their loop-heavy code and frequent as well as expensive calls to libraries, this is often the case. Such a single line hotspot is never explicitely shown by `cProfile` since it might not even contain a function call. \n",
    "This is where the `line_profiler` can play its strengths. It takes specific functions to profile, and it will time the execution of each individual line inside those functions. Typically, a line profiler is useful to inspect the runtimes of lines in a few functions because digging through the timings of each line of code would simply be overwhelming.\n",
    "\n",
    "\n",
    "___References___\n",
    "* [PyPi line-profiler](https://pypi.org/project/line-profiler/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d1243-47c1-4e07-a9ea-8743c806ee48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58ed72-40e8-4dc8-9677-3e5c232a8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30944a3-49ce-4d06-bbeb-33d45c62fb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile profiling/matmul.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "n = 29\n",
    "A = np.random.rand(n, n)\n",
    "B = np.random.rand(n, n)\n",
    "C = np.zeros_like(A)\n",
    "\n",
    "\n",
    "def matmul_ijk(A, B, C):\n",
    "    n = np.shape(A)[0]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(n):\n",
    "                C[i][j] += A[i][k] * B[k][j]\n",
    "                \n",
    "                \n",
    "def matmul_ikj(A, B, C):\n",
    "    n = np.shape(A)[0]\n",
    "    for i in range(n):\n",
    "        for k in range(n):\n",
    "            x = A[i][k]\n",
    "            for j in range(n):\n",
    "                C[i][j] += x * B[k][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79ad72-b596-45ec-be6c-e64eac96ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "n = 100\n",
    "A = np.random.rand(n, n)\n",
    "B = np.random.rand(n, n)\n",
    "C = np.zeros_like(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b1b56-988b-4eef-bd8d-196e5566eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 30 -n 10 matmul_ijk(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f52ae-2fdb-456e-aa67-7ea3313a26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 30 -n 10 matmul_ikj(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb37b52-aa91-4dd7-ba80-c7aee6e6a24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%lprun -f matmul_ijk matmul_ijk(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2765354-a9fd-4f98-9261-c2304503d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f matmul_ikj_rawster matmul_ikj_rawster(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c56082-2136-4dcc-92e8-75a9c96a4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.random.rand(10, 5)\n",
    "print(B.shape)\n",
    "print(len(B[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96168d04-fb18-4146-b423-9623cf0bb074",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `memory_profiler`\n",
    "\n",
    "One more important aspect of profiling is the amount of memory used by functions and instructions. `memory_profiler` is a python module for monitoring memory consumption of a process as well as line-by-line analysis of memory consumption for Python programs. The purpose of this is to find memory leaks and optimize memory usage. Fortunately, it works similarly to `line_profiler`.\n",
    "\n",
    "\n",
    "__References__\n",
    "* [PyPi memory-profiler](https://pypi.org/project/memory-profiler/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5f5a41b-4168-471a-9474-d672675b99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0913e9f-4ba3-4d26-bc76-ded63afbbf5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Measure memory usage of a Python statement\n",
       "\n",
       "Usage, in line mode:\n",
       "  %memit [-r<R>t<T>i<I>] statement\n",
       "\n",
       "Usage, in cell mode:\n",
       "  %%memit [-r<R>t<T>i<I>] setup_code\n",
       "  code...\n",
       "  code...\n",
       "\n",
       "This function can be used both as a line and cell magic:\n",
       "\n",
       "- In line mode you can measure a single-line statement (though multiple\n",
       "  ones can be chained with using semicolons).\n",
       "\n",
       "- In cell mode, the statement in the first line is used as setup code\n",
       "  (executed but not measured) and the body of the cell is measured.\n",
       "  The cell body has access to any variables created in the setup code.\n",
       "\n",
       "Options:\n",
       "-r<R>: repeat the loop iteration <R> times and take the best result.\n",
       "Default: 1\n",
       "\n",
       "-t<T>: timeout after <T> seconds. Default: None\n",
       "\n",
       "-i<I>: Get time information at an interval of I times per second.\n",
       "    Defaults to 0.1 so that there is ten measurements per second.\n",
       "\n",
       "-c: If present, add the memory usage of any children process to the report.\n",
       "\n",
       "-o: If present, return a object containing memit run details\n",
       "\n",
       "-q: If present, be quiet and do not output a result.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "::\n",
       "\n",
       "  In [1]: %memit range(10000)\n",
       "  peak memory: 21.42 MiB, increment: 0.41 MiB\n",
       "\n",
       "  In [2]: %memit range(1000000)\n",
       "  peak memory: 52.10 MiB, increment: 31.08 MiB\n",
       "\n",
       "  In [3]: %%memit l=range(1000000)\n",
       "     ...: len(l)\n",
       "     ...:\n",
       "  peak memory: 52.14 MiB, increment: 0.08 MiB\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/sw/vsc4/VSC/x86_64/generic/jupyterhub-envs/conda/envs/jupyterhub-dask/lib/python3.10/site-packages/memory_profiler.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%memit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7930a2a-8e55-42c3-8ab4-20c5c1668002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Execute a statement under the line-by-line memory profiler from the\n",
       "memory_profiler module.\n",
       "\n",
       "Usage, in line mode:\n",
       "  %mprun -f func1 -f func2 <statement>\n",
       "\n",
       "Usage, in cell mode:\n",
       "  %%mprun -f func1 -f func2 [statement]\n",
       "  code...\n",
       "  code...\n",
       "\n",
       "In cell mode, the additional code lines are appended to the (possibly\n",
       "empty) statement in the first line. Cell mode allows you to easily\n",
       "profile multiline blocks without having to put them in a separate\n",
       "function.\n",
       "\n",
       "The given statement (which doesn't require quote marks) is run via the\n",
       "LineProfiler. Profiling is enabled for the functions specified by the -f\n",
       "options. The statistics will be shown side-by-side with the code through\n",
       "the pager once the statement has completed.\n",
       "\n",
       "Options:\n",
       "\n",
       "-f <function>: LineProfiler only profiles functions and methods it is told\n",
       "to profile.  This option tells the profiler about these functions. Multiple\n",
       "-f options may be used. The argument may be any expression that gives\n",
       "a Python function or method object. However, one must be careful to avoid\n",
       "spaces that may confuse the option parser. Additionally, functions defined\n",
       "in the interpreter at the In[] prompt or via %run currently cannot be\n",
       "displayed.  Write these functions out to a separate file and import them.\n",
       "\n",
       "One or more -f options are required to get any useful results.\n",
       "\n",
       "-T <filename>: dump the text-formatted statistics with the code\n",
       "side-by-side out to a text file.\n",
       "\n",
       "-r: return the LineProfiler object after it has completed profiling.\n",
       "\n",
       "-c: If present, add the memory usage of any children process to the report.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/sw/vsc4/VSC/x86_64/generic/jupyterhub-envs/conda/envs/jupyterhub-dask/lib/python3.10/site-packages/memory_profiler.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mprun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57831266-cd1e-4510-b87a-ef8e773d55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile profiling/memoryprofilerdemo.py\n",
    "\n",
    "def some_sums(n):\n",
    "    twos = [2] * (10**n)\n",
    "    twosum = sum(twos)\n",
    "    del twos\n",
    "    # some long computation\n",
    "    fives = [5] * (10**n)\n",
    "    fivesum = sum(fives)\n",
    "    del fives\n",
    "    return twosum + fivesum\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    some_sums(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed06449-c841-40ac-a0fb-c9da084899ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -m memory_profiler profiling/memoryprofilerdemo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccfc4f-bca0-4b85-9dfc-83d38c9ea6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from profiling.memoryprofilerdemo import some_sums\n",
    "\n",
    "\n",
    "%mprun -f some_sums some_sums(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30255f-b42c-49a8-a8c8-4ec398f9b6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
